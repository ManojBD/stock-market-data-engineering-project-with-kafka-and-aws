# Stock Market Data Engineering Project with Apache Kafka and AWS

## Introduction

This is a Stock Market Data Engineering Project with  Apache Kafka and AWS! This project showcases an end-to-end data engineering pipeline designed to process and analyze historical stock market data using various technologies. The primary objective of this project is to learn how to build a scalable and efficient data pipeline to handle stock market data and derive valuable insights from it.

Throughout this project, I have utilized Python for data processing and analysis tasks, leveraged Amazon Web Services (AWS) for cloud infrastructure, and employed Apache Kafka as a distributed streaming platform for handling data streams. The dataset used consists of historical stock market data.

I completed this project by following a tutorial created by [Darshil Parmar](https://www.youtube.com/watch?v=KerNf0NANMo&ab_channel=DarshilParmar), which provided valuable insights and guidance throughout the development process. A special thanks to Darshil Parmar for his inspiring tutorial.

## Architecture

![Architecture](./Architecture.jpg)

## Technology Used

* Programming Language - Python
* Apache Kafka
* Amazon Web Service (AWS)
  * S3 (Simple Storage Service)
  * Athena
  * Glue Crawler
  * Glue Catalog
  * EC2

## Dataset Used

The dataset used for this project can be found [here](./dataset.csv).

